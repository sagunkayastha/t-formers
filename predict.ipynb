{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoints/G_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Generator(\n",
       "    (start): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(6, 48, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "    (trane256): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down128): Downsample(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (trane128): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down64): Downsample(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (trane64): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down32): Downsample(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (trane32): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up64): Upsample(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (fuse64): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (trand64): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up128): Upsample(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (fuse128): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (trand128): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up256): Upsample(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (fuse256): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (trand256): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trand2562): Sequential(\n",
       "      (0): TransformerEncoder(\n",
       "        (attn): DAttn(\n",
       "          (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (norm): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "          )\n",
       "          (linear): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(48, 1, kernel_size=(7, 7), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    test_img = torch.randn(1,3,).float().cuda()\n",
    "    test_mask = torch.from_numpy(ne_mask[:,:,:512,:512]).float().cuda()\n",
    "    out = model.forward(inp_img.cuda(), test_mask.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import mat73\n",
    "data_path = \"/tng4/users/skayasth/Yearly/2023/Jan/TCEQ/Data_for_PCNN\"\n",
    "File_List = sorted(glob.glob(os.path.join(\n",
    "    data_path, 'Mask_Mean*.mat')))\n",
    "MODIS_AOD_file = mat73.loadmat(os.path.join(\n",
    "    data_path, \"Regridded_MODIS_AOD_4km_Mid_2017_2022_CONUS.mat\"))\n",
    "PUS4k = mat73.loadmat(os.path.join(\n",
    "    data_path, \"Regridded_PUS_4km_2016_CONUS.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= mat73.loadmat(File_List[0])\n",
    "\n",
    "obs = file[f'Mean_PM_STNs_{2018}']\n",
    "obs = np.nan_to_num(obs, nan=np.nan).astype(np.float32)\n",
    "obs = np.einsum('ijk->kij', obs)\n",
    "obs = obs / 450.0\n",
    "obs = np.nan_to_num(obs, nan=1).astype(np.float32)\n",
    "Mask = file[f\"Mask_PM_STNs_{2018}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/tng4/users/skayasth/Yearly/2023/June/TCEQ_Final/Phase1/runs/May_300/maxes.pkl\", 'rb') as f:\n",
    "    arr_loaded = pickle.load(f)\n",
    "\n",
    "\n",
    "_, modis_max, pus_max = arr_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_obs = obs[1]\n",
    "one_obs[one_obs<0] = 0\n",
    "one_mask = Mask[:,:,1]\n",
    "one_modis = MODIS_AOD_file['MODIS_AOD'][:,:,10] / modis_max\n",
    "one_pus = PUS4k['PUS_CONUS'] / pus_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_data = np.array([one_obs, one_modis, one_pus])\n",
    "ne_data = np.expand_dims(ne_data, axis=0)\n",
    "ne_mask = np.array([one_mask, np.ones_like(one_mask), np.ones_like(one_mask)])\n",
    "ne_mask = np.expand_dims(ne_mask, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired padded dimensions\n",
    "\n",
    "def _in(original_array, constant_values=0):\n",
    "    \n",
    "    padded_height, padded_width = 896, 1536\n",
    "\n",
    "\n",
    "    # Get the original array shape\n",
    "    original_height, original_width, original_channels= original_array.shape\n",
    "\n",
    "    # Calculate the required amount of padding\n",
    "    pad_height = padded_height - original_height\n",
    "    pad_width = padded_width - original_width\n",
    "\n",
    "    # Calculate the padding sizes for each dimension\n",
    "    top_padding = pad_height // 2\n",
    "    bottom_padding = pad_height - top_padding\n",
    "    left_padding = pad_width // 2\n",
    "    right_padding = pad_width - left_padding\n",
    "\n",
    "\n",
    "    # Perform the zero-padding\n",
    "    padded_array = np.pad(original_array, ((top_padding, bottom_padding), (left_padding, right_padding), (0, 0)), mode='constant', constant_values=constant_values)\n",
    "\n",
    "    unpadded_array = padded_array[top_padding:top_padding+original_height, left_padding:left_padding+original_width, :]\n",
    "\n",
    "    return padded_array.transpose(2,0,1)\n",
    "\n",
    "ne_data_padded = _in(ne_data[0].transpose(1,2,0)) \n",
    "ne_mask_padded = _in(ne_mask[0].transpose(1,2,0), constant_values=1)\n",
    "\n",
    "ne_data_padded = np.expand_dims(ne_data_padded, axis=0)\n",
    "ne_mask_padded = np.expand_dims(ne_mask_padded, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# np.save(\"input_data.npy\", ne_data)\n",
    "# np.save(\"input_mask.npy\", ne_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x.shape: torch.Size([1, 48, 512, 512])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# test_img =  torch.from_numpy(ne_data_padded).float()\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# test_mask = torch.from_numpy(ne_mask_padded).float()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m inp_img \u001b[39m=\u001b[39m test_img \u001b[39m*\u001b[39m test_mask\n\u001b[0;32m---> 16\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(inp_img\u001b[39m.\u001b[39;49mcuda(), test_mask\u001b[39m.\u001b[39;49mcuda())\n\u001b[1;32m     17\u001b[0m out_22 \u001b[39m=\u001b[39m out  \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m test_mask\u001b[39m.\u001b[39mcuda()) \u001b[39m+\u001b[39m inp_img\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/tng4/users/skayasth/envs/pt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:169\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     kwargs \u001b[39m=\u001b[39m ({},)\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49minputs[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[1;32m    171\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001b[0;32m/tng4/users/skayasth/envs/pt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tng4/users/skayasth/Yearly/2023/July/t-formers/model/network.py:78\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     75\u001b[0m feature \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, mask], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m feature256 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart(feature)\n\u001b[0;32m---> 78\u001b[0m feature256 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrane256(feature256)\n\u001b[1;32m     79\u001b[0m feature128 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown128(feature256)\n\u001b[1;32m     80\u001b[0m feature128 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrane128(feature128)\n",
      "File \u001b[0;32m/tng4/users/skayasth/envs/pt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tng4/users/skayasth/envs/pt/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/tng4/users/skayasth/envs/pt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tng4/users/skayasth/Yearly/2023/July/t-formers/model/network.py:195\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 195\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(x) \u001b[39m+\u001b[39m x\n\u001b[1;32m    196\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed_forward(x)\n\u001b[1;32m    197\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/tng4/users/skayasth/envs/pt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tng4/users/skayasth/Yearly/2023/July/t-formers/model/network.py:334\u001b[0m, in \u001b[0;36mmGAttn.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39mx: b * c * h * w\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m ic(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 334\u001b[0m exit()\n\u001b[1;32m    335\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n\u001b[1;32m    336\u001b[0m Ba, Ca, He, We \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    test_img = torch.from_numpy(ne_data[:,:,:512,:512]).float().cuda()\n",
    "    test_mask = torch.from_numpy(ne_mask[:,:,:512,:512]).float().cuda()\n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "    # test_img =  torch.from_numpy(ne_data_padded).float()\n",
    "    # test_mask = torch.from_numpy(ne_mask_padded).float()\n",
    "    \n",
    "    \n",
    "    \n",
    "    inp_img = test_img * test_mask\n",
    "    \n",
    "    out = model.forward(inp_img.cuda(), test_mask.cuda())\n",
    "    out_22 = out  * (1 - test_mask.cuda()) + inp_img.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(image_array, size=(512, 512), overlap=0.50):\n",
    "    channels, width, height = image_array.shape\n",
    "    stride_width = int(size[0] * (1 - overlap))\n",
    "    stride_height = int(size[1] * (1 - overlap))\n",
    "\n",
    "    cropped_images = []\n",
    "    positions = []\n",
    "\n",
    "    for left in range(0, width - size[0] + 1, stride_width):\n",
    "        for top in range(0, height - size[1] + 1, stride_height):\n",
    "            right = left + size[0]\n",
    "            bottom = top + size[1]\n",
    "            cropped_array = image_array[:, left:right, top:bottom]\n",
    "            cropped_images.append(cropped_array)\n",
    "            positions.append((left, right, top, bottom))\n",
    "            \n",
    "    cropped_array = image_array[:, width-512:, :512]\n",
    "    cropped_images.append(cropped_array)\n",
    "    positions.append((width-512, width, 0, 512))\n",
    "    cropped_array = image_array[:, width-512:, height-512:]\n",
    "    cropped_images.append(cropped_array)\n",
    "    positions.append((width-512, width, height-512, height))\n",
    "\n",
    "    return np.array(cropped_images), positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_images,pos = split_image(ne_data[0], size=(512, 512), overlap=0.20)\n",
    "cropped_masks,posm = split_image(ne_mask[0], size=(512, 512), overlap=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outs = []\n",
    "    for img, mask in zip(cropped_images,cropped_masks):\n",
    "        \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        \n",
    "        test_img = torch.from_numpy(img).float().cuda()\n",
    "        test_mask = torch.from_numpy(mask).float().cuda()\n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "    # # test_img =  torch.from_numpy(ne_data_padded).float()\n",
    "    # # test_mask = torch.from_numpy(ne_mask_padded).float()\n",
    "    \n",
    "    \n",
    "    \n",
    "        inp_img = test_img * test_mask\n",
    "    \n",
    "        out = model.forward(inp_img.cuda(), test_mask.cuda())\n",
    "        \n",
    "        out_22 = out  * (1 - test_mask.cuda()) + inp_img.cuda()\n",
    "        \n",
    "        outs.append(out_22[0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = cropped_images.shape[0]\n",
    "num_cols = int(np.sqrt(num_images))\n",
    "num_rows = int(np.ceil(num_images / num_cols))\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < num_images:\n",
    "        ax.imshow(cropped_images[i].transpose(1, 2, 0)[:, :, -1])\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = cropped_images.shape[0]\n",
    "num_cols = int(np.sqrt(num_images))\n",
    "num_rows = int(np.ceil(num_images / num_cols))\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < num_images:\n",
    "        ax.imshow(outs[i].transpose(1, 2, 0)[:, :, 0])\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs\n",
    "main_out = np.zeros((3, 768, 1456))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(pos):\n",
    "    top, bot, left, right = var\n",
    "   \n",
    "    main_out[0, top:bot, left:right] = outs[i][0]\n",
    "    if i == 7:\n",
    "        break\n",
    "# main_out[0, :512, 256:768] = outs[1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_out[0, 266:778, 0:512].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(main_out.transpose(1,2,0)[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ne_data[0].transpose(1,2,0)[:, :, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
